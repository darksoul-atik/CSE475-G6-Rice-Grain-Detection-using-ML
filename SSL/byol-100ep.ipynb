{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e55c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === BYOL IMPLEMENTATION ===\n",
    "import torch, torch.nn as nn, torch.nn.functional as F, copy\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np, matplotlib.pyplot as plt, seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Config\n",
    "DATA_DIR = '/kaggle/input/riceds-original/Original'\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Data augmentations (two strong views)\n",
    "class BYOLTransform:\n",
    "    def __init__(self, size=224):\n",
    "        normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(size),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ColorJitter(0.8, 0.8, 0.8, 0.2),\n",
    "            transforms.RandomGrayscale(p=0.2),\n",
    "            transforms.GaussianBlur(kernel_size=9),\n",
    "            transforms.ToTensor(),\n",
    "            normalize\n",
    "        ])\n",
    "    def __call__(self, x): return self.transform(x), self.transform(x)\n",
    "\n",
    "class BYOLDataset(datasets.ImageFolder):\n",
    "    def __getitem__(self, index):\n",
    "        path, _ = self.samples[index]\n",
    "        img = self.loader(path).convert('RGB')\n",
    "        return self.transform(img)\n",
    "\n",
    "train_dataset = BYOLDataset(DATA_DIR, transform=BYOLTransform())\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Encoder\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        base = models.resnet50(pretrained=False)\n",
    "        self.backbone = nn.Sequential(*list(base.children())[:-1])\n",
    "        self.feature_dim = 2048\n",
    "\n",
    "    def forward(self, x): return self.backbone(x).squeeze()\n",
    "\n",
    "# MLP heads\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim), nn.BatchNorm1d(hidden_dim), nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, out_dim)\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "# BYOL model\n",
    "class BYOL(nn.Module):\n",
    "    def __init__(self, encoder, proj_dim=128, hidden_dim=512):\n",
    "        super().__init__()\n",
    "        self.online_encoder = encoder\n",
    "        self.online_projector = MLP(encoder.feature_dim, hidden_dim, proj_dim)\n",
    "        self.online_predictor = MLP(proj_dim, hidden_dim, proj_dim)\n",
    "\n",
    "        self.target_encoder = copy.deepcopy(encoder)\n",
    "        self.target_projector = copy.deepcopy(self.online_projector)\n",
    "\n",
    "        for p in self.target_encoder.parameters(): p.requires_grad = False\n",
    "        for p in self.target_projector.parameters(): p.requires_grad = False\n",
    "\n",
    "    def update_target(self, m=0.996):\n",
    "        for o, t in zip(self.online_encoder.parameters(), self.target_encoder.parameters()):\n",
    "            t.data = t.data * m + o.data * (1. - m)\n",
    "        for o, t in zip(self.online_projector.parameters(), self.target_projector.parameters()):\n",
    "            t.data = t.data * m + o.data * (1. - m)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        z1 = self.online_projector(self.online_encoder(x1))\n",
    "        z2 = self.online_projector(self.online_encoder(x2))\n",
    "        p1 = self.online_predictor(z1)\n",
    "        p2 = self.online_predictor(z2)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            t1 = self.target_projector(self.target_encoder(x1))\n",
    "            t2 = self.target_projector(self.target_encoder(x2))\n",
    "        return p1, p2, t1.detach(), t2.detach()\n",
    "\n",
    "def byol_loss(p, z):\n",
    "    p = F.normalize(p, dim=-1)\n",
    "    z = F.normalize(z, dim=-1)\n",
    "    return 2 - 2 * (p * z).sum(dim=1).mean()\n",
    "\n",
    "# Pretraining\n",
    "encoder = Encoder().to(DEVICE)\n",
    "model = BYOL(encoder).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for (x1, x2) in tqdm(train_loader, desc=f\"BYOL Epoch {epoch+1}\"):\n",
    "        x1, x2 = x1.to(DEVICE), x2.to(DEVICE)\n",
    "        p1, p2, t1, t2 = model(x1, x2)\n",
    "        loss = byol_loss(p1, t2) + byol_loss(p2, t1)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        model.update_target()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}: Loss={total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "torch.save(model.online_encoder.state_dict(), \"byol_encoder.pth\")\n",
    "\n",
    "# === Linear Evaluation ===\n",
    "class LinearClassifier(nn.Module):\n",
    "    def __init__(self, feat_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(feat_dim, num_classes)\n",
    "    def forward(self, x): return self.fc(x)\n",
    "\n",
    "# Freeze encoder\n",
    "eval_encoder = Encoder().to(DEVICE)\n",
    "eval_encoder.load_state_dict(torch.load(\"byol_encoder.pth\"))\n",
    "for param in eval_encoder.parameters(): param.requires_grad = False\n",
    "eval_encoder.eval()\n",
    "\n",
    "classifier = LinearClassifier(2048, 38).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(classifier.parameters(), lr=1e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "eval_tf = transforms.Compose([\n",
    "    transforms.Resize(256), transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(), transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n",
    "dataset = datasets.ImageFolder(DATA_DIR, transform=eval_tf)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "train_ds, test_ds = random_split(dataset, [train_size, len(dataset)-train_size])\n",
    "train_loader_eval = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "test_loader_eval = DataLoader(test_ds, batch_size=64, shuffle=False)\n",
    "\n",
    "# Train classifier\n",
    "for epoch in range(10):\n",
    "    classifier.train()\n",
    "    for x, y in train_loader_eval:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        with torch.no_grad(): features = eval_encoder(x).squeeze()\n",
    "        logits = classifier(features)\n",
    "        loss = loss_fn(logits, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluate\n",
    "classifier.eval()\n",
    "y_true, y_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader_eval:\n",
    "        x = x.to(DEVICE)\n",
    "        features = eval_encoder(x).squeeze()\n",
    "        preds = torch.argmax(classifier(features), dim=1).cpu().numpy()\n",
    "        y_pred.extend(preds)\n",
    "        y_true.extend(y.numpy())\n",
    "\n",
    "print(\"\\n BYOL Evaluation:\")\n",
    "print(classification_report(y_true, y_pred, digits=4))\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens')\n",
    "plt.title(\"BYOL Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
