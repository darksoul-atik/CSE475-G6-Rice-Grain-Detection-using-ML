{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d70576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === MOCO IMPLEMENTATION ===\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np, matplotlib.pyplot as plt, seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Config\n",
    "DATA_DIR = '/kaggle/input/riceds-original/Original'\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# MoCo Augmentations\n",
    "moco_tf = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(0.4, 0.4, 0.4, 0.1),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# MoCo Dataset (two views)\n",
    "class MoCoDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, transform):\n",
    "        self.base = datasets.ImageFolder(root, transform=transform)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path, _ = self.base.samples[index]\n",
    "        img = self.base.loader(path)\n",
    "        return self.transform(img), self.transform(img)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base)\n",
    "\n",
    "train_dataset = MoCoDataset(DATA_DIR, moco_tf)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Encoder + projection\n",
    "def get_encoder():\n",
    "    resnet = models.resnet50(pretrained=False)\n",
    "    encoder = nn.Sequential(*list(resnet.children())[:-1])  # Remove FC\n",
    "    return encoder, resnet.fc.in_features\n",
    "\n",
    "class MoCo(nn.Module):\n",
    "    def __init__(self, dim=128, K=4096, m=0.999, T=0.07):\n",
    "        super().__init__()\n",
    "        self.K, self.m, self.T = K, m, T\n",
    "        self.encoder_q, feat_dim = get_encoder()\n",
    "        self.encoder_k, _ = get_encoder()\n",
    "        self.fc_q = nn.Linear(feat_dim, dim)\n",
    "        self.fc_k = nn.Linear(feat_dim, dim)\n",
    "\n",
    "        self.register_buffer(\"queue\", torch.randn(dim, K))\n",
    "        self.queue = F.normalize(self.queue, dim=0)\n",
    "        self.register_buffer(\"queue_ptr\", torch.zeros(1, dtype=torch.long))\n",
    "\n",
    "        for param_q, param_k in zip(self.encoder_q.parameters(), self.encoder_k.parameters()):\n",
    "            param_k.data.copy_(param_q.data)\n",
    "            param_k.requires_grad = False\n",
    "\n",
    "        for param_q, param_k in zip(self.fc_q.parameters(), self.fc_k.parameters()):\n",
    "            param_k.data.copy_(param_q.data)\n",
    "            param_k.requires_grad = False\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _momentum_update_key_encoder(self):\n",
    "        for param_q, param_k in zip(self.encoder_q.parameters(), self.encoder_k.parameters()):\n",
    "            param_k.data = param_k.data * self.m + param_q.data * (1. - self.m)\n",
    "        for param_q, param_k in zip(self.fc_q.parameters(), self.fc_k.parameters()):\n",
    "            param_k.data = param_k.data * self.m + param_q.data * (1. - self.m)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _dequeue_and_enqueue(self, keys):\n",
    "        keys = concat_all_gather(keys)\n",
    "        batch_size = keys.shape[0]\n",
    "        ptr = int(self.queue_ptr)\n",
    "        self.queue[:, ptr:ptr+batch_size] = keys.T\n",
    "        ptr = (ptr + batch_size) % self.K\n",
    "        self.queue_ptr[0] = ptr\n",
    "\n",
    "    def forward(self, im_q, im_k):\n",
    "        q = F.normalize(self.fc_q(self.encoder_q(im_q).squeeze()), dim=1)\n",
    "        with torch.no_grad():\n",
    "            self._momentum_update_key_encoder()\n",
    "            k = F.normalize(self.fc_k(self.encoder_k(im_k).squeeze()), dim=1)\n",
    "\n",
    "        l_pos = torch.einsum('nc,nc->n', [q, k]).unsqueeze(-1)\n",
    "        l_neg = torch.einsum('nc,ck->nk', [q, self.queue.clone().detach()])\n",
    "        logits = torch.cat([l_pos, l_neg], dim=1)\n",
    "        labels = torch.zeros(logits.size(0), dtype=torch.long).to(DEVICE)\n",
    "        logits /= self.T\n",
    "        self._dequeue_and_enqueue(k)\n",
    "        return logits, labels\n",
    "\n",
    "@torch.no_grad()\n",
    "def concat_all_gather(tensor):\n",
    "    return tensor  # No multi-GPU needed here\n",
    "\n",
    "# Training\n",
    "model = MoCo().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for im_q, im_k in tqdm(train_loader, desc=f\"MoCo Epoch {epoch+1}\"):\n",
    "        im_q, im_k = im_q.to(DEVICE), im_k.to(DEVICE)\n",
    "        logits, labels = model(im_q, im_k)\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1} Loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "torch.save(model.encoder_q.state_dict(), \"moco_encoder.pth\")\n",
    "\n",
    "# === Linear Evaluation ===\n",
    "class LinearClassifier(nn.Module):\n",
    "    def __init__(self, feat_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(feat_dim, num_classes)\n",
    "\n",
    "    def forward(self, x): return self.fc(x)\n",
    "\n",
    "# Load encoder\n",
    "encoder = get_encoder()[0]\n",
    "encoder.load_state_dict(torch.load(\"moco_encoder.pth\"))\n",
    "encoder.eval()\n",
    "for param in encoder.parameters(): param.requires_grad = False\n",
    "encoder.to(DEVICE)\n",
    "\n",
    "classifier = LinearClassifier(2048, 38).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(classifier.parameters(), lr=1e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "eval_tf = transforms.Compose([\n",
    "    transforms.Resize(256), transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(), transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n",
    "dataset = datasets.ImageFolder(DATA_DIR, transform=eval_tf)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "train_ds, test_ds = random_split(dataset, [train_size, len(dataset) - train_size])\n",
    "train_loader_eval = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "test_loader_eval = DataLoader(test_ds, batch_size=64, shuffle=False)\n",
    "\n",
    "# Train classifier\n",
    "for epoch in range(10):\n",
    "    classifier.train()\n",
    "    for x, y in train_loader_eval:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        with torch.no_grad(): features = encoder(x).squeeze()\n",
    "        logits = classifier(features)\n",
    "        loss = loss_fn(logits, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluate\n",
    "classifier.eval()\n",
    "y_true, y_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader_eval:\n",
    "        x = x.to(DEVICE)\n",
    "        features = encoder(x).squeeze()\n",
    "        preds = torch.argmax(classifier(features), dim=1).cpu().numpy()\n",
    "        y_pred.extend(preds)\n",
    "        y_true.extend(y.numpy())\n",
    "\n",
    "print(\"\\n MoCo Evaluation:\")\n",
    "print(classification_report(y_true, y_pred, digits=4))\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Oranges')\n",
    "plt.title(\"MoCo Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
